import torch
from safetensors import safe_open
from safetensors.torch import save_file
import pickle
import glob
from tqdm import tqdm
from datasets import Dataset
from pprint import pprint

# read all pickle files under the directory
def read_pickle_files(path):
    files = glob.glob(path + "/*.txt")
    return files

all_files = read_pickle_files("/home/wl356/big_picture_rds/wl356/infoseek/infoseek_images/images")

print(all_files[:3])
# all_files = all_files[:100]

# construct a dataset from all_files
ds = Dataset.from_dict({"file": all_files})


# Prepare ElasticSearch
from elasticsearch import Elasticsearch, helpers

# Password for the 'elastic' user generated by Elasticsearch
ELASTIC_PASSWORD = "EKJ8kIbmMg=e6sI5vikP"

es = Elasticsearch(
    "https://localhost:9200",
    ca_certs="/home/wl356/cvnlp_rds/wl356/elasticsearch-8.7.0/config/certs/http_ca.crt",
    basic_auth=("elastic", ELASTIC_PASSWORD)
)

# Successful response!
es.info()

index_name = "image_captions"

# delete the current index
# es.indices.delete(index=index_name)


def process_examples(examples):
    all_files = examples["file"]

    actions = []

    # read pickle files and save as safe tensors
    for file in all_files:
        with open(file, "r") as f:
            caption = f.read()
        
        file_id = file.split("/")[-1].replace(".txt", "")
        
        action = {
            '_op_type': "index",
            '_index': index_name,
            '_id': file_id,
            '_source': {
                'caption': caption,
            }
        }
        actions.append(action)
    
    # print(actions)
    res = helpers.bulk(es, actions, request_timeout=120)
    # print(f"number of success {res[0]}")
    if res[0] != len(actions):
        print("errors", res[1])
    print(f"Successfully indexed {len(actions)} items into ES.")


ds.map(process_examples, batched=True, batch_size=1000, num_proc=16)


queries = [
    'oven_01952954.JPEG',
    'oven_00356114.JPEG',
]
docs = [
    {
        '_index': index_name,
        '_id': q,
    } for q in queries
]
resp = es.mget(index=index_name, docs=docs)
for doc in resp['docs']:
    if doc['found']:
        print(doc['_id'], doc['_source']['caption'])
    else:
        print(doc['_id'], 'not found')
