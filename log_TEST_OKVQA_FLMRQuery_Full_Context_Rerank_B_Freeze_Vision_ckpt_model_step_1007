[rank: 0] Seed set to 2022
[38;20m[INFO] - runway_for_ml.experiment : Config file saved to experiments/TEST_OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision_ckpt_model_step_1007/test/config.json[0m
[38;20m[INFO] - runway_for_ml.experiment : init wandb logger with the following settings: {'entity': 'byrne-lab', 'project': 'PreFLMR MLMI', 'tags': ['OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision', 'test', 'NoBaseModelInfo'], 'id': 'stbilufk', 'resume': 'must'}[0m
[38;20m[INFO] - runway_for_ml.data_module.data_pipeline : Using dummy data? False[0m
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.
[38;20m[INFO] - src.data_ops.custom_datasets.vg_datasets : Running PrepareDataloaders[0m
[38;20m[INFO] - src.data_ops.custom_datasets.base_datasets : initialising OKVQADatasetForDPR...[0m
[38;20m[INFO] - src.data_ops.custom_datasets.okvqa_datasets : passages prepared. used 2.6702880859375e-05 secs.[0m
[38;20m[INFO] - src.data_ops.custom_datasets.vg_datasets : [Data Statistics]: test data loader: test/OKVQADatasetForDPR.test 316[0m
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[38;20m[INFO] - root : Train with LoRA = False[0m
[38;20m[INFO] - src.executors.Reranker_base_executor : Loading static retrieval results from /home/fz288/rds/hpc-work/PreFLMR/experiments/TEST_OKVQA_FLMR_Index_2/test/_test_OKVQADatasetForDPR.test_predictions_rank_0.pkl[0m
[38;20m[INFO] - src.executors.Reranker_base_executor : Loading static retrieval results from /home/fz288/rds/hpc-work/PreFLMR/experiments/TEST_OKVQA_FLMR_Index/test/_test_OKVQADatasetForDPR.train_predictions_rank_0.pkl[0m
[38;20m[INFO] - src.executors.Reranker_base_executor : Loaded 14055 static retrieval results.[0m
/home/fz288/rds/hpc-work/PreFLMR/VQA/lib/python3.8/site-packages/lightning_fabric/connector.py:563: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[38;20m[INFO] - runway_for_ml.experiment : additional arguments passed to trainer: {'accelerator': 'auto', 'devices': 'auto', 'limit_test_batches': 65, 'precision': 'bf16', 'strategy': 'ddp_find_unused_parameters_true', 'default_root_dir': PosixPath('experiments/TEST_OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision_ckpt_model_step_1007/test'), 'logger': [<pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f4f9fa1fe80>, <pytorch_lightning.loggers.wandb.WandbLogger object at 0x7f4f9f94d280>]}[0m
[31;20m[ERROR] - runway_for_ml.experiment : No checkpoints are specified.[0m
[31;20m[ERROR] - runway_for_ml.experiment : No checkpoint found. Please check your config file.[0m
[31;20m[ERROR] - runway_for_ml.experiment : !!! Testing continues with untrained checkpoints (also useful when applying pre-trained checkpoints directly)[0m
You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[rank: 0] Seed set to 2022
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

wandb: Currently logged in as: fz288 (byrne-lab). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in ./wandb/run-20240607_124233-stbilufk
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run TEST_OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision_ckpt_model_step_1007
wandb: ‚≠êÔ∏è View project at https://wandb.ai/byrne-lab/PreFLMR%20MLMI
wandb: üöÄ View run at https://wandb.ai/byrne-lab/PreFLMR%20MLMI/runs/stbilufk
[38;20m[INFO] - src.executors.Reranker_base_executor : Preparing 114809 passage data in id2doc...[0m
Runway main started.
input value {} is not a number, parse to string.
Configuration Loaded.
{'args': {'config': 'configs/Rerank/initial_experiments/okvqa_full_context_retrieve_rerank.jsonnet',
          'experiment_name': 'TEST_OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision_ckpt_model_step_1007',
          'from_experiment': '',
          'log_prediction_tables': False,
          'log_prediction_tables_with_images': False,
          'mode': 'test',
          'modules': [],
          'opts': ['train.load_model_path=/home/fz288/rds/hpc-work/PreFLMR/experiments/OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision/train/saved_models/model_step_1007.ckpt'],
          'override': False,
          'reset': False,
          'tags': ['OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision',
                   'test'],
          'test_suffix': '',
          'use_dummy_data': False,
          'wandb_artifacts': 'weizhelin/vqa-images-open/VQAv2-Images:v0'},
 'data_pipeline': {'do_inspect': True,
                   'name': 'MergeDataPipeline',
                   'regenerate': False,
                   'transforms': {'output:PrepareDataloaders': {'cache': True,
                                                                'input_node': ['process:ConcatenatePassageDatasets',
                                                                               'process:WrapOutputIntoKeys'],
                                                                'regenerate': True,
                                                                'setup_kwargs': {'datasets_config': {'test': [{'dataset_type': 'OKVQADatasetForDPR',
                                                                                                               'split': 'test',
                                                                                                               'use_column': 'okvqa_data'}],
                                                                                                     'train': [{'dataset_type': 'OKVQADatasetForDPR',
                                                                                                                'split': 'train',
                                                                                                                'use_column': 'okvqa_data'}],
                                                                                                     'valid': [{'dataset_type': 'OKVQADatasetForDPR',
                                                                                                                'split': 'test',
                                                                                                                'use_column': 'okvqa_data'}]},
                                                                                 'extra_columns': {'passages': 'train_passages',
                                                                                                   'valid_passages': 'valid_passages'},
                                                                                 'feature_extractor_config': {},
                                                                                 'image_processor_config': {'vit_image_processor': {'ImageProcessorClass': 'AutoImageProcessor',
                                                                                                                                    'ImageProcessorModelVersion': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k'}},
                                                                                 'pass_columns': {'test_passages': 'test_passages',
                                                                                                  'train_passages': 'train_passages',
                                                                                                  'valid_passages': 'valid_passages',
                                                                                                  'vqa_data_with_dpr_output': 'okvqa_data'},
                                                                                 'tokenizer_config': {'decoder_tokenizer': {'SPECIAL_TOKENS': {'additional_special_tokens': []},
                                                                                                                            'TokenizerClass': 'FLMRContextEncoderTokenizer',
                                                                                                                            'TokenizerModelVersion': 'LinWeizheDragon/PreFLMR_ViT-B'},
                                                                                                      'tokenizer': {'SPECIAL_TOKENS': {'additional_special_tokens': []},
                                                                                                                    'TokenizerClass': 'FLMRQueryEncoderTokenizer',
                                                                                                                    'TokenizerModelVersion': 'LinWeizheDragon/PreFLMR_ViT-B'}}},
                                                                'transform_name': 'PrepareDataloaders'},
                                  'process:ConcatenatePassageDatasets': {'cache': True,
                                                                         'input_node': ['process:LoadOKVQAData'],
                                                                         'regenerate': False,
                                                                         'setup_kwargs': {'concat_splits': {'test_passages': [True],
                                                                                                            'train_passages': [True],
                                                                                                            'valid_passages': [True]},
                                                                                          'names': ['okvqa_passages']},
                                                                         'transform_name': 'ConcatenatePassageDatasets'},
                                  'process:LoadOKVQAData': {'cache': True,
                                                            'regenerate': False,
                                                            'setup_kwargs': {'add_instruction': ['Using '
                                                                                                 'the '
                                                                                                 'provided '
                                                                                                 'image, '
                                                                                                 'obtain '
                                                                                                 'documents '
                                                                                                 'that '
                                                                                                 'address '
                                                                                                 'the '
                                                                                                 'subsequent '
                                                                                                 'question: ',
                                                                                                 'Retrieve '
                                                                                                 'documents '
                                                                                                 'that '
                                                                                                 'provide '
                                                                                                 'an '
                                                                                                 'answer '
                                                                                                 'to '
                                                                                                 'the '
                                                                                                 'question '
                                                                                                 'alongside '
                                                                                                 'the '
                                                                                                 'image: ',
                                                                                                 'Extract '
                                                                                                 'documents '
                                                                                                 'linked '
                                                                                                 'to '
                                                                                                 'the '
                                                                                                 'question '
                                                                                                 'provided '
                                                                                                 'in '
                                                                                                 'conjunction '
                                                                                                 'with '
                                                                                                 'the '
                                                                                                 'image: ',
                                                                                                 'Utilizing '
                                                                                                 'the '
                                                                                                 'given '
                                                                                                 'image, '
                                                                                                 'obtain '
                                                                                                 'documents '
                                                                                                 'that '
                                                                                                 'respond '
                                                                                                 'to '
                                                                                                 'the '
                                                                                                 'following '
                                                                                                 'question: ',
                                                                                                 'Using '
                                                                                                 'the '
                                                                                                 'given '
                                                                                                 'image, '
                                                                                                 'access '
                                                                                                 'documents '
                                                                                                 'that '
                                                                                                 'provide '
                                                                                                 'insights '
                                                                                                 'into '
                                                                                                 'the '
                                                                                                 'following '
                                                                                                 'question: ',
                                                                                                 'Obtain '
                                                                                                 'documents '
                                                                                                 'that '
                                                                                                 'correspond '
                                                                                                 'to '
                                                                                                 'the '
                                                                                                 'inquiry '
                                                                                                 'alongside '
                                                                                                 'the '
                                                                                                 'provided '
                                                                                                 'image: ',
                                                                                                 'With '
                                                                                                 'the '
                                                                                                 'provided '
                                                                                                 'image, '
                                                                                                 'gather '
                                                                                                 'documents '
                                                                                                 'that '
                                                                                                 'offer '
                                                                                                 'a '
                                                                                                 'solution '
                                                                                                 'to '
                                                                                                 'the '
                                                                                                 'question: ',
                                                                                                 'Utilizing '
                                                                                                 'the '
                                                                                                 'given '
                                                                                                 'image, '
                                                                                                 'obtain '
                                                                                                 'documents '
                                                                                                 'that '
                                                                                                 'respond '
                                                                                                 'to '
                                                                                                 'the '
                                                                                                 'following '
                                                                                                 'question: '],
                                                                             'data_path': 'BByrneLab/multi_task_multi_modal_knowledge_retrieval_benchmark_M2KR///OKVQA_data',
                                                                             'image_root_folder': '/home/fz288/rds/rds-cvnlp-hirYTW1FQIw/shared_space/vqa_data/KBVQA_data/ok-vqa',
                                                                             'passage_path': 'BByrneLab/multi_task_multi_modal_knowledge_retrieval_benchmark_M2KR///OKVQA_passages'},
                                                            'transform_name': 'LoadPreprocessedData_v2'},
                                  'process:WrapOutputIntoKeys': {'cache': True,
                                                                 'input_node': ['process:LoadOKVQAData'],
                                                                 'regenerate': True,
                                                                 'setup_kwargs': {'output_keys': ['okvqa_data']},
                                                                 'transform_name': 'WrapOutputIntoKeys'}}},
 'eval': {'eval_op_name': 'Your eval op name'},
 'executor': {'ExecutorClass': 'RerankerBaseExecutor',
              'init_kwargs': {'index_splits': ['train', 'valid', 'test'],
                              'use_data_node': 'output:PrepareDataloaders',
                              'validation_indexing_source': ['okvqa_passages']}},
 'experiment_name': 'TEST_OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision_ckpt_model_step_1007',
 'from_experiment': '',
 'log_prediction_tables': False,
 'meta': {'DATA_FOLDER': 'data',
          'EXPERIMENT_FOLDER': 'experiments',
          'TENSORBOARD_FOLDER': 'tensorboards',
          'WANDB': {'CACHE_DIR': 'cache/wandb_cache/',
                    'entity': 'byrne-lab',
                    'project': 'PreFLMR MLMI',
                    'tags': ['OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision',
                             'test']},
          'default_cache_dir': 'cache/',
          'logger_enable': ['tensorboard', 'wandb'],
          'platform_type': 'pytorch',
          'seed': 2022,
          'use_versioning': False},
 'metrics': [{'name': 'compute_rerank_DPR_scores'},
             {'name': 'compute_rerank_DPR_scores_with_pos_ids'}],
 'mode': 'test',
 'model_config': {'Ks': [5, 10, 20, 50, 100],
                  'decoder_input_modules': {'module_list': [{'option': 'default',
                                                             'separation_tokens': {'end': '',
                                                                                   'start': ''},
                                                             'type': 'KnowledgeInput'}],
                                            'postprocess_module_list': [{'option': 'default',
                                                                         'type': 'PostProcessFLMRItemInputTokenization'}]},
                  'docs_to_rerank': 100,
                  'fusion_multiplier': 1,
                  'index_files': {'embedding_path': '',
                                  'index_path': '',
                                  'static_results': ['/home/fz288/rds/hpc-work/PreFLMR/experiments/TEST_OKVQA_FLMR_Index_2/test/_test_OKVQADatasetForDPR.test_predictions_rank_0.pkl',
                                                     '/home/fz288/rds/hpc-work/PreFLMR/experiments/TEST_OKVQA_FLMR_Index/test/_test_OKVQADatasetForDPR.train_predictions_rank_0.pkl']},
                  'input_modules': {'module_list': [{'option': 'from_file',
                                                     'type': 'VisionInput'},
                                                    {'option': 'default',
                                                     'separation_tokens': {'end': '',
                                                                           'start': ''},
                                                     'type': 'InstructionInput'}],
                                    'postprocess_module_list': [{'option': 'default',
                                                                 'type': 'PostProcessVisionInputProcessing'},
                                                                {'option': 'default',
                                                                 'type': 'PostProcessFLMRQuestionInputTokenization'}]},
                  'max_decoder_source_length': 512,
                  'max_source_length': 32,
                  'modules': ['separate_query_and_item_encoders',
                              'full_context_reranker',
                              'train_with_retrieved_docs'],
                  'nbits': 8,
                  'num_negative_samples': 39,
                  'output_modules': {'module_list': [{'option': 'default',
                                                      'type': 'SimilarityOutput'}],
                                     'postprocess_module_list': [{'option': 'default',
                                                                  'type': 'PostProcessConcatenateLabels'}]},
                  'prepend_tokens': {'item_encoder': '', 'query_encoder': ''},
                  'pretrained': 1,
                  'reranker_config': {'RerankerClass': 'FullContextRerankModel',
                                      'base_model': 'FLMR',
                                      'cross_encoder_config_base': 'bert-base-uncased',
                                      'cross_encoder_max_position_embeddings': 750,
                                      'cross_encoder_num_hidden_layers': 1,
                                      'loss_fn': 'BCE',
                                      'max_decoder_source_length': 512,
                                      'max_query_length': 32,
                                      'pretrain_config_class': 'FLMRConfig',
                                      'pretrain_model_version': 'LinWeizheDragon/PreFLMR_ViT-B'},
                  'retriever_config': {'ConfigClass': 'FLMRConfig',
                                       'ModelClass': 'FLMRModelForRetrieval',
                                       'ModelVersion': 'LinWeizheDragon/PreFLMR_ViT-B',
                                       'base_model': 'FLMR'}},
 'override': False,
 'reset': False,
 'test': {'batch_size': 16,
          'checkpoint_name': '',
          'load_best_model': False,
          'load_model_path': '',
          'num_dataloader_workers': 0,
          'trainer_paras': {'accelerator': 'auto',
                            'devices': 'auto',
                            'limit_test_batches': 65,
                            'precision': 'bf16',
                            'strategy': 'ddp_find_unused_parameters_true'}},
 'test_suffix': '',
 'train': {'batch_size': 1,
           'early_stopping_callback_paras': {'mode': 'min',
                                             'patience': 3,
                                             'verbose': True},
           'load_model_path': '/home/fz288/rds/hpc-work/PreFLMR/experiments/OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision/train/saved_models/model_step_1007.ckpt',
           'model_checkpoint_callback_paras': {'auto_insert_metric_name': False,
                                               'filename': 'model_step_{step}',
                                               'mode': 'min',
                                               'monitor': 'valid/OKVQADatasetForDPR.test/loss',
                                               'save_last': True,
                                               'save_on_train_epoch_end': False,
                                               'save_top_k': 5,
                                               'verbose': True},
           'num_dataloader_workers': 4,
           'optimizer_config': {'optimizer_name': 'AdamW',
                                'optimizer_params': {'eps': 1e-08, 'lr': 1e-05},
                                'scheduler': 'none',
                                'scheduler_params': {'num_warmup_steps': 0}},
           'trainer_paras': {'accelerator': 'auto',
                             'accumulate_grad_batches': 8,
                             'check_val_every_n_epoch': None,
                             'devices': 'auto',
                             'limit_val_batches': 50,
                             'log_every_n_steps': 10,
                             'max_epochs': -1,
                             'precision': 'bf16',
                             'strategy': 'ddp_find_unused_parameters_true',
                             'val_check_interval': 1000}},
 'use_dummy_data': False,
 'valid': {'batch_size': 16, 'num_dataloader_workers': 0}}
User modules imported
Runway Testing...
All seeds have been set to 2022
test-directory: experiments/TEST_OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision_ckpt_model_step_1007/test
Using loggers: ['tensorboard', 'wandb']
[<pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f4f9fa1fe80>, <pytorch_lightning.loggers.wandb.WandbLogger object at 0x7f4f9f94d280>]
Saving testing results to: experiments/TEST_OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision_ckpt_model_step_1007/test/test_case.txt
======================================================================================================================================================
                                                                     MODEL CONFIG                                                                     
{'Ks': [5, 10, 20, 50, 100], 'decoder_input_modules': {'module_list': [{'option': 'default', 'separation_tokens': {'end': '', 'start': ''}, 'type': 'KnowledgeInput'}], 'postprocess_module_list': [{'option': 'default', 'type': 'PostProcessFLMRItemInputTokenization'}]}, 'docs_to_rerank': 100, 'fusion_multiplier': 1, 'index_files': {'embedding_path': '', 'index_path': '', 'static_results': ['/home/fz288/rds/hpc-work/PreFLMR/experiments/TEST_OKVQA_FLMR_Index_2/test/_test_OKVQADatasetForDPR.test_predictions_rank_0.pkl', '/home/fz288/rds/hpc-work/PreFLMR/experiments/TEST_OKVQA_FLMR_Index/test/_test_OKVQADatasetForDPR.train_predictions_rank_0.pkl']}, 'input_modules': {'module_list': [{'option': 'from_file', 'type': 'VisionInput'}, {'option': 'default', 'separation_tokens': {'end': '', 'start': ''}, 'type': 'InstructionInput'}], 'postprocess_module_list': [{'option': 'default', 'type': 'PostProcessVisionInputProcessing'}, {'option': 'default', 'type': 'PostProcessFLMRQuestionInputTokenization'}]}, 'max_decoder_source_length': 512, 'max_source_length': 32, 'modules': ['separate_query_and_item_encoders', 'full_context_reranker', 'train_with_retrieved_docs'], 'nbits': 8, 'num_negative_samples': 39, 'output_modules': {'module_list': [{'option': 'default', 'type': 'SimilarityOutput'}], 'postprocess_module_list': [{'option': 'default', 'type': 'PostProcessConcatenateLabels'}]}, 'prepend_tokens': {'item_encoder': '', 'query_encoder': ''}, 'pretrained': 1, 'reranker_config': {'RerankerClass': 'FullContextRerankModel', 'base_model': 'FLMR', 'cross_encoder_config_base': 'bert-base-uncased', 'cross_encoder_max_position_embeddings': 750, 'cross_encoder_num_hidden_layers': 1, 'loss_fn': 'BCE', 'max_decoder_source_length': 512, 'max_query_length': 32, 'pretrain_config_class': 'FLMRConfig', 'pretrain_model_version': 'LinWeizheDragon/PreFLMR_ViT-B'}, 'retriever_config': {'ConfigClass': 'FLMRConfig', 'ModelClass': 'FLMRModelForRetrieval', 'ModelVersion': 'LinWeizheDragon/PreFLMR_ViT-B', 'base_model': 'FLMR'}}
======================================================================================================================================================
                                                                   OPTIMIZER CONFIG                                                                   
None
======================================================================================================================================================
                                                                   TRAINING CONFIG                                                                    
{}
======================================================================================================================================================
                                                                     TEST CONFIG                                                                      
{'batch_size': 16, 'checkpoint_name': '', 'load_best_model': False, 'load_model_path': '', 'num_dataloader_workers': 0, 'trainer_paras': {'accelerator': 'auto', 'devices': 'auto', 'limit_test_batches': 65, 'precision': 'bf16', 'strategy': 'ddp_find_unused_parameters_true'}}
======================================================================================================================================================
PrepareDataloaders
{'cache': True, 'input_node': ['process:ConcatenatePassageDatasets', 'process:WrapOutputIntoKeys'], 'regenerate': True, 'setup_kwargs': {'datasets_config': {'test': [{'dataset_type': 'OKVQADatasetForDPR', 'split': 'test', 'use_column': 'okvqa_data'}], 'train': [{'dataset_type': 'OKVQADatasetForDPR', 'split': 'train', 'use_column': 'okvqa_data'}], 'valid': [{'dataset_type': 'OKVQADatasetForDPR', 'split': 'test', 'use_column': 'okvqa_data'}]}, 'extra_columns': {'passages': 'train_passages', 'valid_passages': 'valid_passages'}, 'feature_extractor_config': {}, 'image_processor_config': {'vit_image_processor': {'ImageProcessorClass': 'AutoImageProcessor', 'ImageProcessorModelVersion': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k'}}, 'pass_columns': {'test_passages': 'test_passages', 'train_passages': 'train_passages', 'valid_passages': 'valid_passages', 'vqa_data_with_dpr_output': 'okvqa_data'}, 'tokenizer_config': {'decoder_tokenizer': {'SPECIAL_TOKENS': {'additional_special_tokens': []}, 'TokenizerClass': 'FLMRContextEncoderTokenizer', 'TokenizerModelVersion': 'LinWeizheDragon/PreFLMR_ViT-B'}, 'tokenizer': {'SPECIAL_TOKENS': {'additional_special_tokens': []}, 'TokenizerClass': 'FLMRQueryEncoderTokenizer', 'TokenizerModelVersion': 'LinWeizheDragon/PreFLMR_ViT-B'}}}, 'transform_name': 'PrepareDataloaders'}
dict_keys([])
attempting to check cache exist: cache/process:ConcatenatePassageDatasets-4c3114b2ec6656f111735f2284653362.hf --> True
attempting to check cache exist: cache/process:LoadOKVQAData-f810a301c4921c239584cdd5426ec7ac.hf --> True
Load process:ConcatenatePassageDatasets-4c3114b2ec6656f111735f2284653362 from disk cache
Data loaded from cache/process:ConcatenatePassageDatasets-4c3114b2ec6656f111735f2284653362.hf
WrapOutputIntoKeys
{'cache': True, 'input_node': ['process:LoadOKVQAData'], 'regenerate': True, 'setup_kwargs': {'output_keys': ['okvqa_data']}, 'transform_name': 'WrapOutputIntoKeys'}
dict_keys([])
Load process:LoadOKVQAData-f810a301c4921c239584cdd5426ec7ac from disk cache
Data loaded from cache/process:LoadOKVQAData-f810a301c4921c239584cdd5426ec7ac.hf
Node: process:WrapOutputIntoKeys 
Execute Transform: WrapOutputIntoKeys
wrapped columns: dict_keys(['okvqa_data'])
Data saved to cache/process:WrapOutputIntoKeys-d736da6bd13f28721d585150bcfd0db6.pkl
Node: output:PrepareDataloaders 
Execute Transform: PrepareDataloaders
Received data columns: dict_keys(['test_passages', 'train_passages', 'valid_passages', 'okvqa_data'])
test_passages: Dataset({
    features: ['passage_id', 'passage_content', 'title', 'source_name'],
    num_rows: 114809
})
train_passages: Dataset({
    features: ['passage_id', 'passage_content', 'title', 'source_name'],
    num_rows: 114809
})
valid_passages: Dataset({
    features: ['passage_id', 'passage_content', 'title', 'source_name'],
    num_rows: 114809
})
okvqa_data: {'train': Dataset({
    features: ['answers', 'gold_answer', 'question', 'question_id', 'img_path', 'img_key_full', 'img_key', 'img_file_name', 'img', 'img_caption', 'objects', 'img_ocr', 'pos_item_ids', 'pos_item_contents', 'related_item_ids', '__index_level_0__', 'instruction'],
    num_rows: 9009
}), 'valid': Dataset({
    features: ['answers', 'gold_answer', 'question', 'question_id', 'img_path', 'img_key_full', 'img_key', 'img_file_name', 'img', 'img_caption', 'objects', 'img_ocr', 'pos_item_ids', 'pos_item_contents', 'related_item_ids', '__index_level_0__', 'instruction'],
    num_rows: 5046
}), 'test': Dataset({
    features: ['answers', 'gold_answer', 'question', 'question_id', 'img_path', 'img_key_full', 'img_key', 'img_file_name', 'img', 'img_caption', 'objects', 'img_ocr', 'pos_item_ids', 'pos_item_contents', 'related_item_ids', '__index_level_0__', 'instruction'],
    num_rows: 5046
}), 'train_passages': Dataset({
    features: ['passage_id', 'passage_content', 'title'],
    num_rows: 114809
}), 'valid_passages': Dataset({
    features: ['passage_id', 'passage_content', 'title'],
    num_rows: 114809
}), 'test_passages': Dataset({
    features: ['passage_id', 'passage_content', 'title'],
    num_rows: 114809
})}
'Dataset' object has no attribute 'keys'
'Dataset' object has no attribute 'keys'
'Dataset' object has no attribute 'keys'
First 5 image paths in dataset 'okvqa_data[train]' of length 9009 are valid.
First 5 image paths in dataset 'okvqa_data[valid]' of length 5046 are valid.
First 5 image paths in dataset 'okvqa_data[test]' of length 5046 are valid.
'img_path'
extra_column passages extra_column_from train_passages
extra_column valid_passages extra_column_from valid_passages
available ids 114809
{'test_passages': 'test_passages', 'train_passages': 'train_passages', 'valid_passages': 'valid_passages', 'vqa_data_with_dpr_output': 'okvqa_data'}
Data saved to cache/output:PrepareDataloaders-dc03d5b49c83f6684ace8dfcc369d2bf.pkl
Load output:PrepareDataloaders-dc03d5b49c83f6684ace8dfcc369d2bf from program cache
Load output:PrepareDataloaders-dc03d5b49c83f6684ace8dfcc369d2bf from program cache
0
Loading lookup table...
Rank 0 Done loading lookup table.
formatting the test passages:   0%|          | 0/114809 [00:00<?, ?it/s]formatting the test passages:   2%|‚ñè         | 1866/114809 [00:00<00:06, 18653.75it/s]formatting the test passages:   3%|‚ñé         | 3775/114809 [00:00<00:05, 18905.78it/s]formatting the test passages:   5%|‚ñå         | 5749/114809 [00:00<00:05, 19286.02it/s]formatting the test passages:   7%|‚ñã         | 7748/114809 [00:00<00:05, 19561.15it/s]formatting the test passages:   8%|‚ñä         | 9730/114809 [00:00<00:05, 19651.41it/s]formatting the test passages:  10%|‚ñà         | 11713/114809 [00:00<00:05, 19709.89it/s]formatting the test passages:  12%|‚ñà‚ñè        | 13699/114809 [00:00<00:05, 19757.71it/s]formatting the test passages:  14%|‚ñà‚ñé        | 15708/114809 [00:00<00:04, 19863.01it/s]formatting the test passages:  15%|‚ñà‚ñå        | 17703/114809 [00:00<00:04, 19887.79it/s]formatting the test passages:  17%|‚ñà‚ñã        | 19692/114809 [00:01<00:04, 19781.19it/s]formatting the test passages:  19%|‚ñà‚ñâ        | 21687/114809 [00:01<00:04, 19830.43it/s]formatting the test passages:  21%|‚ñà‚ñà        | 23671/114809 [00:01<00:04, 19819.55it/s]formatting the test passages:  22%|‚ñà‚ñà‚ñè       | 25671/114809 [00:01<00:04, 19873.27it/s]formatting the test passages:  24%|‚ñà‚ñà‚ñç       | 27672/114809 [00:01<00:04, 19912.30it/s]formatting the test passages:  26%|‚ñà‚ñà‚ñå       | 29675/114809 [00:01<00:04, 19946.44it/s]formatting the test passages:  28%|‚ñà‚ñà‚ñä       | 31674/114809 [00:01<00:04, 19958.30it/s]formatting the test passages:  29%|‚ñà‚ñà‚ñâ       | 33691/114809 [00:01<00:04, 20019.11it/s]formatting the test passages:  31%|‚ñà‚ñà‚ñà       | 35702/114809 [00:01<00:03, 20043.42it/s]formatting the test passages:  33%|‚ñà‚ñà‚ñà‚ñé      | 37715/114809 [00:01<00:03, 20068.96it/s]formatting the test passages:  35%|‚ñà‚ñà‚ñà‚ñç      | 39722/114809 [00:02<00:03, 20040.41it/s]formatting the test passages:  36%|‚ñà‚ñà‚ñà‚ñã      | 41727/114809 [00:02<00:03, 19998.18it/s]formatting the test passages:  38%|‚ñà‚ñà‚ñà‚ñä      | 43727/114809 [00:02<00:03, 19928.43it/s]formatting the test passages:  40%|‚ñà‚ñà‚ñà‚ñâ      | 45737/114809 [00:02<00:03, 19977.37it/s]formatting the test passages:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 47756/114809 [00:02<00:03, 20039.03it/s]formatting the test passages:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 49760/114809 [00:02<00:03, 20012.26it/s]formatting the test passages:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 51770/114809 [00:02<00:03, 20036.69it/s]formatting the test passages:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 53774/114809 [00:02<00:03, 20033.27it/s]formatting the test passages:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 55787/114809 [00:02<00:02, 20062.01it/s]formatting the test passages:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 57794/114809 [00:02<00:02, 20059.11it/s]formatting the test passages:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 59811/114809 [00:03<00:02, 20092.01it/s]formatting the test passages:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 61831/114809 [00:03<00:02, 20123.84it/s]formatting the test passages:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 63846/114809 [00:03<00:02, 20128.76it/s]formatting the test passages:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 65859/114809 [00:03<00:02, 20082.59it/s]formatting the test passages:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 67868/114809 [00:03<00:02, 20027.85it/s]formatting the test passages:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 69871/114809 [00:03<00:02, 19987.04it/s]formatting the test passages:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 71882/114809 [00:03<00:02, 20022.42it/s]formatting the test passages:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 73888/114809 [00:03<00:02, 20033.31it/s]formatting the test passages:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 75892/114809 [00:03<00:01, 20018.89it/s]formatting the test passages:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 77894/114809 [00:03<00:01, 20010.87it/s]formatting the test passages:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 79896/114809 [00:04<00:01, 19989.30it/s]formatting the test passages:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 81895/114809 [00:04<00:01, 19938.90it/s]formatting the test passages:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 83889/114809 [00:04<00:01, 19937.80it/s]formatting the test passages:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 85884/114809 [00:04<00:01, 19938.88it/s]formatting the test passages:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 87878/114809 [00:04<00:01, 19706.80it/s]formatting the test passages:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 89891/114809 [00:04<00:01, 19830.58it/s]formatting the test passages:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 91903/114809 [00:04<00:01, 19915.46it/s]formatting the test passages:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 93909/114809 [00:04<00:01, 19956.57it/s]formatting the test passages:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 95924/114809 [00:04<00:00, 20012.01it/s]formatting the test passages:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 97926/114809 [00:04<00:00, 19879.43it/s]formatting the test passages:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 99915/114809 [00:05<00:00, 19879.55it/s]formatting the test passages:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 101904/114809 [00:05<00:00, 19868.94it/s]formatting the test passages:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 103903/114809 [00:05<00:00, 19902.55it/s]formatting the test passages:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 105912/114809 [00:05<00:00, 19956.29it/s]formatting the test passages:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 107921/114809 [00:05<00:00, 19995.22it/s]formatting the test passages:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 109921/114809 [00:05<00:00, 19988.15it/s]formatting the test passages:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 111920/114809 [00:05<00:00, 19960.65it/s]formatting the test passages:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 113919/114809 [00:05<00:00, 19968.94it/s]formatting the test passages: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 114809/114809 [00:05<00:00, 19924.35it/s]
[38;20m[INFO] - src.executors.Reranker_base_executor : passages from the source okvqa_passages has 114809[0m
[38;20m[INFO] - src.executors.Reranker_base_executor : Passages prepared.[0m
[38;20m[INFO] - src.executors.Reranker_base_executor : tokenizer lengths = 30522 and 30522[0m
[38;20m[INFO] - src.executors.Reranker_base_executor : Loading from /home/fz288/rds/hpc-work/PreFLMR/experiments/OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision/train/saved_models/model_step_1007.ckpt[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
SLURM auto-requeueing enabled. Setting signal handlers.
/home/fz288/rds/hpc-work/PreFLMR/VQA/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
Testing: |          | 0/? [00:00<?, ?it/s]Testing:   0%|          | 0/65 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/65 [00:00<?, ?it/s]x
y
Testing DataLoader 0:   2%|‚ñè         | 1/65 [00:04<05:16,  0.20it/s]x
y
Testing DataLoader 0:   3%|‚ñé         | 2/65 [00:07<04:10,  0.25it/s]x
y
Testing DataLoader 0:   5%|‚ñç         | 3/65 [00:10<03:46,  0.27it/s]x
y
Testing DataLoader 0:   6%|‚ñå         | 4/65 [00:13<03:30,  0.29it/s]x
y
Testing DataLoader 0:   8%|‚ñä         | 5/65 [00:16<03:20,  0.30it/s]x
y
Testing DataLoader 0:   9%|‚ñâ         | 6/65 [00:19<03:13,  0.31it/s]x
y
Testing DataLoader 0:  11%|‚ñà         | 7/65 [00:22<03:06,  0.31it/s]x
y
Testing DataLoader 0:  12%|‚ñà‚ñè        | 8/65 [00:25<03:01,  0.31it/s]x
y
Testing DataLoader 0:  14%|‚ñà‚ñç        | 9/65 [00:28<02:56,  0.32it/s]x
y
Testing DataLoader 0:  15%|‚ñà‚ñå        | 10/65 [00:31<02:52,  0.32it/s]x
y
Testing DataLoader 0:  17%|‚ñà‚ñã        | 11/65 [00:34<02:47,  0.32it/s]x
y
Testing DataLoader 0:  18%|‚ñà‚ñä        | 12/65 [00:37<02:44,  0.32it/s]x
y
Testing DataLoader 0:  20%|‚ñà‚ñà        | 13/65 [00:40<02:40,  0.32it/s]x
y
Testing DataLoader 0:  22%|‚ñà‚ñà‚ñè       | 14/65 [00:43<02:36,  0.33it/s]x
y
Testing DataLoader 0:  23%|‚ñà‚ñà‚ñé       | 15/65 [00:46<02:34,  0.32it/s]x
y
Testing DataLoader 0:  25%|‚ñà‚ñà‚ñç       | 16/65 [00:49<02:31,  0.32it/s]x
y
Testing DataLoader 0:  26%|‚ñà‚ñà‚ñå       | 17/65 [00:52<02:27,  0.33it/s]x
y
Testing DataLoader 0:  28%|‚ñà‚ñà‚ñä       | 18/65 [00:55<02:24,  0.33it/s]x
y
Testing DataLoader 0:  29%|‚ñà‚ñà‚ñâ       | 19/65 [00:58<02:20,  0.33it/s]x
y
Testing DataLoader 0:  31%|‚ñà‚ñà‚ñà       | 20/65 [01:01<02:17,  0.33it/s]x
y
Testing DataLoader 0:  32%|‚ñà‚ñà‚ñà‚ñè      | 21/65 [01:03<02:14,  0.33it/s]x
y
Testing DataLoader 0:  34%|‚ñà‚ñà‚ñà‚ñç      | 22/65 [01:06<02:10,  0.33it/s]x
y
Testing DataLoader 0:  35%|‚ñà‚ñà‚ñà‚ñå      | 23/65 [01:09<02:07,  0.33it/s]x
y
Testing DataLoader 0:  37%|‚ñà‚ñà‚ñà‚ñã      | 24/65 [01:12<02:04,  0.33it/s]x
y
Testing DataLoader 0:  38%|‚ñà‚ñà‚ñà‚ñä      | 25/65 [01:15<02:00,  0.33it/s]x
y
Testing DataLoader 0:  40%|‚ñà‚ñà‚ñà‚ñà      | 26/65 [01:18<01:57,  0.33it/s]x
y
Testing DataLoader 0:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 27/65 [01:21<01:54,  0.33it/s]x
y
Testing DataLoader 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 28/65 [01:24<01:51,  0.33it/s]x
y
Testing DataLoader 0:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 29/65 [01:27<01:48,  0.33it/s]x
y
Testing DataLoader 0:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 30/65 [01:30<01:45,  0.33it/s]x
y
Testing DataLoader 0:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 31/65 [01:33<01:42,  0.33it/s]x
y
Testing DataLoader 0:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 32/65 [01:36<01:39,  0.33it/s]x
y
Testing DataLoader 0:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 33/65 [01:38<01:35,  0.33it/s]x
y
Testing DataLoader 0:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 34/65 [01:41<01:32,  0.33it/s]x
y
Testing DataLoader 0:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 35/65 [01:44<01:29,  0.33it/s]x
y
Testing DataLoader 0:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 36/65 [01:47<01:26,  0.33it/s]x
y
Testing DataLoader 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 37/65 [01:50<01:23,  0.33it/s]x
y
Testing DataLoader 0:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 38/65 [01:53<01:20,  0.33it/s]x
y
Testing DataLoader 0:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 39/65 [01:56<01:17,  0.34it/s]x
y
Testing DataLoader 0:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 40/65 [01:59<01:14,  0.34it/s]x
y
Testing DataLoader 0:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 41/65 [02:02<01:11,  0.34it/s]x
y
Testing DataLoader 0:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 42/65 [02:05<01:08,  0.34it/s]x
y
Testing DataLoader 0:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 43/65 [02:07<01:05,  0.34it/s]x
y
Testing DataLoader 0:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 44/65 [02:10<01:02,  0.34it/s]x
y
Testing DataLoader 0:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 45/65 [02:13<00:59,  0.34it/s]x
y
Testing DataLoader 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 46/65 [02:16<00:56,  0.34it/s]x
y
Testing DataLoader 0:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 47/65 [02:19<00:53,  0.34it/s]x
y
Testing DataLoader 0:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 48/65 [02:22<00:50,  0.34it/s]x
y
Testing DataLoader 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 49/65 [02:25<00:47,  0.34it/s]x
y
Testing DataLoader 0:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 50/65 [02:28<00:44,  0.34it/s]x
y
Testing DataLoader 0:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 51/65 [02:31<00:41,  0.34it/s]x
y
Testing DataLoader 0:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 52/65 [02:34<00:38,  0.34it/s]x
y
Testing DataLoader 0:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 53/65 [02:37<00:35,  0.34it/s]x
y
Testing DataLoader 0:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 54/65 [02:40<00:32,  0.34it/s]x
y
Testing DataLoader 0:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 55/65 [02:42<00:29,  0.34it/s]x
y
Testing DataLoader 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 56/65 [02:45<00:26,  0.34it/s]x
y
Testing DataLoader 0:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 57/65 [02:48<00:23,  0.34it/s]x
y
Testing DataLoader 0:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 58/65 [02:51<00:20,  0.34it/s]x
y
Testing DataLoader 0:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 59/65 [02:54<00:17,  0.34it/s]x
y
Testing DataLoader 0:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 60/65 [02:57<00:14,  0.34it/s]x
y
Testing DataLoader 0:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 61/65 [03:00<00:11,  0.34it/s]x
y
Testing DataLoader 0:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 62/65 [03:03<00:08,  0.34it/s]x
y
Testing DataLoader 0:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 63/65 [03:05<00:05,  0.34it/s]x
y
Testing DataLoader 0:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 64/65 [03:08<00:02,  0.34it/s]x
y
Testing DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65/65 [03:11<00:00,  0.34it/s]/home/fz288/rds/hpc-work/PreFLMR/VQA/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
[38;20m[INFO] - src.executors.Reranker_base_executor : reading global step of the checkpoint...[0m
[38;20m[INFO] - src.executors.Reranker_base_executor : Evaluation results [test]: {'_test/OKVQADatasetForDPR.test/loss': 2.89827561378479, '_test/OKVQADatasetForDPR.test/epoch': 0}[0m
{'_test/OKVQADatasetForDPR.test/epoch': 0,
 '_test/OKVQADatasetForDPR.test/loss': 2.89827561378479}
{'predictions/step_0_MODE(test)_SET(_test/OKVQADatasetForDPR.test)_rank(0)': <wandb.data_types.Table object at 0x7f4f9f97f9a0>}
Testing DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65/65 [03:12<00:00,  0.34it/s][38;20m[INFO] - runway_for_ml.utils.eval_recorder : test-evaluation EvalRecorder saved to experiments/TEST_OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision_ckpt_model_step_1007/test/test-evaluation/eval_recorder-sample_log.json, experiments/TEST_OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision_ckpt_model_step_1007/test/test-evaluation/eval_recorder-stats_log.json, experiments/TEST_OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision_ckpt_model_step_1007/test/test-evaluation/eval_recorder-meta_config.json[0m

Test evaluation recorder saved to experiments/TEST_OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision_ckpt_model_step_1007/test/test-evaluation
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            Test metric                       DataLoader 0
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
_test/OKVQADatasetForDPR.test/epoch                0.0
_test/OKVQADatasetForDPR.test/loss          2.89827561378479
         valid/loss_epoch                   2.898275375366211
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
wandb: - 0.000 MB of 0.000 MB uploadedwandb: \ 0.000 MB of 0.041 MB uploadedwandb: | 0.000 MB of 0.041 MB uploadedwandb: / 0.000 MB of 0.041 MB uploadedwandb: - 0.000 MB of 0.041 MB uploadedwandb: \ 0.041 MB of 0.041 MB uploadedwandb: 
wandb: Run history:
wandb:               epoch ‚ñÅ
wandb: trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÅ
wandb:    valid/loss_epoch ‚ñÅ
wandb:     valid/loss_step ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÑ
wandb: 
wandb: Run summary:
wandb:               epoch 0
wandb: trainer/global_step 0
wandb:    valid/loss_epoch 2.89828
wandb:     valid/loss_step 2.59481
wandb: 
wandb: üöÄ View run TEST_OKVQA_FLMRQuery_Full_Context_Rerank_B_Freeze_Vision_ckpt_model_step_1007 at: https://wandb.ai/byrne-lab/PreFLMR%20MLMI/runs/stbilufk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/byrne-lab/PreFLMR%20MLMI
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240607_124233-stbilufk/logs
